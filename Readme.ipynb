{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f8fcef",
   "metadata": {},
   "source": [
    "# Lokales RAG-ChatGPT für Unternehmensdokumente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b276a",
   "metadata": {},
   "source": [
    "\n",
    "Ein anpassbares, vollständig offline laufendes Frage-Antwort-System für unternehmensinterne Dokumente (z. B. Finanzberichte). Das Projekt basiert auf Retrieval-Augmented Generation (RAG), lokalen Embeddings und einem lokal laufenden Sprachmodell über Ollama.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed84528",
   "metadata": {},
   "source": [
    "## Projektmotivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3018a07",
   "metadata": {},
   "source": [
    "\n",
    "Unternehmen haben berechtigte Sorgen, wenn es um die Preisgabe sensibler Daten an externe Cloud-Dienste wie ChatGPT geht. Dieses Projekt demonstriert eine vollständig lokale Lösung für interaktive Dokumentenanalyse:\n",
    "\n",
    "- Keine Datenübertragung an externe Server\n",
    "- Kein API-Key notwendig\n",
    "- Volle Kontrolle über Verarbeitung und Speicherung\n",
    "\n",
    "Ziel ist es, eine dialogfähige Anwendung bereitzustellen, die interne Dokumente wie Finanzberichte analysieren und daraus Fragen beantworten kann.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255111e7",
   "metadata": {},
   "source": [
    "## Funktionsumfang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4a27e",
   "metadata": {},
   "source": [
    "\n",
    "- Verarbeitung von PDF-Dokumenten mit LangChain\n",
    "- Erstellung semantischer Embeddings mit SentenceTransformer (MiniLM)\n",
    "- Speicherung in einer lokalen Vektordatenbank (Chroma)\n",
    "- Einsatz eines lokal laufenden LLMs via Ollama (z. B. Mistral)\n",
    "- Optional: Bedienoberfläche mit Streamlit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10448b",
   "metadata": {},
   "source": [
    "## Einrichtung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46605895",
   "metadata": {},
   "source": [
    "\n",
    "1. Installiere die Abhängigkeiten aus `requirements.txt`:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "2. Starte das lokale Sprachmodell mit Ollama:\n",
    "```bash\n",
    "ollama run mistral\n",
    "```\n",
    "\n",
    "3. Starte die Streamlit-Anwendung (optional):\n",
    "```bash\n",
    "streamlit run rag_chat_app_.py\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20e4a1",
   "metadata": {},
   "source": [
    "## Beispielanfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4725c",
   "metadata": {},
   "source": [
    "\n",
    "**Frage:**  \n",
    "Wie hoch ist der Gesamtumsatz im Q1 2025?\n",
    "\n",
    "**Antwort des Systems:**  \n",
    "Der Gesamtumsatz im Q1 2025 beträgt €1,507m.\n",
    "\n",
    "**Antwort im UI:**  \n",
    "<img src=\"screenshots/Frage_Antwort.png\" alt=\"Antwort im UI\" width=\"600\"/>\n",
    "\n",
    "**Fundstelle im PDF:**  \n",
    "<img src=\"screenshots/Quelle.png\" alt=\"Antwort im UI\" width=\"600\"/>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75be35",
   "metadata": {},
   "source": [
    "## Ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da214b2",
   "metadata": {},
   "source": [
    "\n",
    "Dieses Projekt zeigt, dass moderne KI-Technologien wie RAG auch vollständig lokal und datenschutzkonform eingesetzt werden können. Die Anwendung eignet sich ideal für sensible Einsatzbereiche wie Personalwesen, Controlling oder strategische Analysen auf Basis interner Daten.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504734d",
   "metadata": {},
   "source": [
    "## Stichworte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9e170",
   "metadata": {},
   "source": [
    "\n",
    "Retrieval-Augmented Generation, LangChain, Ollama, PDF-Dokumentenanalyse, lokale KI, Datenschutz, Chroma, SentenceTransformer, Unternehmensdaten, Mistral\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
